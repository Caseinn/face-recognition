<div align="center">

# ğŸ­ Face Recognition with ArcFace

*Deep learning face recognition system powered by FaceNet (InceptionResnetV1) with ArcFace loss*

[![Demo](https://img.shields.io/badge/ğŸ¤—-Live%20Demo-yellow)](https://huggingface.co/spaces/ditorifki/face-recognition-demo)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-Academic-green.svg)]()

</div>

---

## ğŸ‘¥ Team

<table align="center">
  <tr>
    <td align="center"><b>Fathan Andi Kartagama</b><br/>122140055</td>
    <td align="center"><b>Rahmat Aldi Nasda</b><br/>122140077</td>
    <td align="center"><b>Dito Rifki Irawan</b><br/>122140153</td>
  </tr>
</table>

---

## ğŸ“– Overview

This project implements a state-of-the-art face recognition system using **ArcFace loss** to learn highly discriminative facial embeddings. The system supports two powerful backbone architectures:

- **FaceNet (InceptionResnetV1)** - Pretrained on VGGFace2 for robust face recognition
- **DeiT-Small** - Transformer-based architecture for comparison

---

## âœ¨ Key Features

<table>
  <tr>
    <td>ğŸ§ </td>
    <td><b>Dual Architecture</b><br/>FaceNet & DeiT support</td>
    <td>ğŸ¯</td>
    <td><b>High Accuracy</b><br/>99% validation accuracy</td>
  </tr>
  <tr>
    <td>ğŸ‘¤</td>
    <td><b>Auto Detection</b><br/>MediaPipe face detection</td>
    <td>ğŸŒ</td>
    <td><b>Web Interface</b><br/>Interactive Gradio demo</td>
  </tr>
  <tr>
    <td>ğŸš€</td>
    <td><b>Transfer Learning</b><br/>VGGFace2 & ImageNet pretrained</td>
    <td>âš¡</td>
    <td><b>Real-time</b><br/>Fast inference pipeline</td>
  </tr>
  <tr>
    <td>ğŸ“Š</td>
    <td><b>Attendance System</b><br/>Automated logging with timestamps</td>
    <td>ğŸ”„</td>
    <td><b>K-Fold Training</b><br/>5-fold cross validation</td>
  </tr>
</table>

---

## ğŸ“ Project Structure

```
face-recognition/
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â””â”€â”€ Train_Cropped/          # 70 identity classes cropped via crop.ipynb
â”‚   â””â”€â”€ Train/ 
â”‚
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”œâ”€â”€ best_facenet_arcface_kfold5.pth
â”‚   â”œâ”€â”€ best_deit_small_patch16_224.fb_in1k_arcface_kfold5.pth
â”‚   â””â”€â”€ label_map.json
â”‚
â”œâ”€â”€ ğŸ“‚ train/
â”‚   â”œâ”€â”€ train_facenet.ipynb     # FaceNet training with K-Fold
â”‚   â””â”€â”€ train_deit.ipynb        # DeiT training with K-Fold
â”‚
â”œâ”€â”€ ğŸ“„ app.py                    # Gradio web interface with attendance
â”œâ”€â”€ ğŸ“„ attendance_log.csv        # Attendance records
â”œâ”€â”€ ğŸ““ crop.ipynb
â”œâ”€â”€ ğŸ““ evaluation.ipynb           # Evaluate trained face recognition model on test dataset
â””â”€â”€ ğŸ“ README.md
```

---

## ğŸ“Š Model Performance

<div align="center">

| ğŸ—ï¸ Architecture | ğŸ“ˆ Val Accuracy | ğŸ¯ Pretrained |
|:---------------:|:---------------:|:----------------:|
| **InceptionResnetV1 + ArcFace** | 99% | VGGFace2 |
| **DeiT-Small + ArcFace** | 81% | ImageNet-1k |

</div>

<table align="center">
  <tr>
    <td align="center"><b>FaceNet (InceptionResnetV1)</b><br/><img src="train/output_facenet.png" alt="FaceNet Training Curve" width="60%"/></td>
    <td align="center"><b>DeiT-Small</b><br/><img src="train/output_deit.png" alt="DeiT-Small Training Curve" width="68%"/></td>
  </tr>
</table>

---

## ğŸš€ Getting Started

### Installation

```bash
# Clone the repository
git clone https://github.com/Caseinn/face-recognition.git
cd face-recognition

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Quick Start

**ğŸ“ Training**
```bash
# Launch Jupyter and open training notebooks
jupyter notebook train/train_facenet.ipynb   # For FaceNet
jupyter notebook train/train_deit.ipynb      # For DeiT
```

**ğŸ”® Inference & Attendance**
```bash
# Run local Gradio interface
python app.py
# Access at http://localhost:7860
```

**ğŸŒ Try Online**

No installation needed! Try our live demo:

<div align="center">

**[ğŸ¤— Launch Live Demo](https://huggingface.co/spaces/ditorifki/attendance-system)**

</div>

---

## âš™ï¸ Technical Details

### Architecture Configuration

**FaceNet (InceptionResnetV1) - Main Model:**
```yaml
Backbone: InceptionResnetV1 (VGGFace2 pretrained)
Input Size: 160 Ã— 160
Embedding Dimension: 512
ArcFace Scale (s): 25.0
ArcFace Margin (m): 0.30
Optimizer: Adam (lr=1e-4)
Scheduler: CosineAnnealingLR
Training Strategy: 5-Fold Cross Validation
```

**DeiT-Small - Comparison Model:**
```yaml
Backbone: DeiT-Small (ImageNet pretrained)
Input Size: 224 Ã— 224
Embedding Dimension: 512
ArcFace Scale (s): 25.0
ArcFace Margin (m): 0.30
Optimizer: Adam (lr=1e-4)
Scheduler: CosineAnnealingLR
Training Strategy: 5-Fold Cross Validation
```

### Dataset Statistics

```yaml
Total Classes: 70
Total Images: 283
Face Detection: MediaPipe (dual-pass detection)
Face Crop:
  Size: 384x384
  Margin: 15%
Augmentation:
  - Random Horizontal Flip: 50%
  - Random Affine Transform: 60%
    - Rotation: Â±20Â°
    - Translation: Â±10%
    - Scale: 0.85â€“1.15
  - Random Perspective: 30%
    - Distortion Scale: 0.2
  - Gaussian Blur: [20%, 40%]
  - Color Jitter:
      Brightness: Â±30%
      Contrast: Â±30%
      Saturation: Â±30%
      Hue: Â±10%
  - Random Grayscale: 15%
  - Motion Blur: 20%
  - Gaussian Noise: 40%
    - Std: 0.05
  - ISO Noise: 40%
  - Multiplicative Noise: 40%
  - Brightness Enhancement: 30% 
  - Random Shadow: 20%
  - JPEG Compression: 20%
    - Quality: 40â€“80
  - Random Erasing: 30%
    - Area: 2%â€“15% 
```

---

## ğŸ§® ArcFace Loss Function

ArcFace enhances face discrimination by adding an angular margin to the cosine similarity:

```
L = -log(e^(sÂ·cos(Î¸+m)) / (e^(sÂ·cos(Î¸+m)) + Î£e^(sÂ·cos(Î¸))))
```

**Where:**
- `s` = scale parameter (25.0)
- `m` = angular margin (0.30)
- `Î¸` = angle between feature and weight vectors

**Benefits:**
- âœ… Enhanced intra-class compactness
- âœ… Improved inter-class separability
- âœ… Better generalization to unseen faces
- âœ… State-of-the-art performance on face verification

---

## ğŸ“‹ Attendance System

The system includes an automated attendance logging feature:

**Features:**
- âœ… Real-time face recognition
- âœ… Automatic timestamp recording
- âœ… Confidence score logging
- âœ… CSV export for records
- âœ… Live attendance log viewer

**Log Format:**
```csv
Timestamp,Name,Confidence,Status
2024-12-01 14:30:45,John Doe,0.9523,Success
```

---

## ğŸ› ï¸ Built With

<div align="center">

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)

</div>

**Core Libraries:**
- [facenet-pytorch](https://github.com/timesler/facenet-pytorch) - FaceNet implementation
- [timm](https://github.com/huggingface/pytorch-image-models) - DeiT & Vision Transformers
- [MediaPipe](https://mediapipe.dev/) - Face Detection
- [Gradio](https://gradio.app/) - Web Interface
- [ArcFace](https://arxiv.org/abs/1801.07698) - Loss Function Implementation

---

## ğŸ“š Course Information

<div align="center">

**Deep Learning (Pembelajaran Mendalam)**  
Semester 7 | Final Project

</div>

---

<div align="center">

*[â­ Star this repo](https://github.com/Caseinn/face-recognition) if you find it helpful!*

</div>
